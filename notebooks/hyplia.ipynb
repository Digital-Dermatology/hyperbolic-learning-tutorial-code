{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperbolic Learning in Action: Practice\n",
    "\n",
    "In this notebook, we are going to train, evaluate, and compare three Convolutional Neural Networks (CNNs):\n",
    "\n",
    "1. an ordinary, fully Euclidean one;\n",
    "2. one with the last layer in hyperbolic space;\n",
    "3. a fully hyperbolic network.\n",
    "\n",
    "We will use:\n",
    "\n",
    "- the CIFAR-10 and CIFAR-100 datasets, whereas the first is chosen for its simplicity and the second because it exhibits *hierarchical* structure;\n",
    "- the hyperbolic learning library `HypLL` for the hyperbolic layers, due to its ease of use.\n",
    "\n",
    "We will visualize data representations in the Euclidean and hyperbolic space.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Start by adding the project's root to the Python path for custom functions."
   ],
   "id": "74ca198f368823f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))"
   ],
   "id": "9352bec5b326238c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the `torch` device and seeds for reproducibility.",
   "id": "d19dfe3197bd7118"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from src.utils.torch_utils import get_available_device, set_seeds\n",
    "\n",
    "device = torch.device(get_available_device())\n",
    "set_seeds(42)"
   ],
   "id": "fb05e8538d74623a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Get the datasets.\n",
    "\n",
    "Since this is a demonstration, and it does not use hyperparameter tuning, it is ok to work only with one split for training and one for evaluation, i.e. testing."
   ],
   "id": "96b93ecb7b740c21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=(0.5, 0.5, 0.5),\n",
    "            std=(0.5, 0.5, 0.5),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "classes = train_dataset.classes\n",
    "assert test_dataset.classes == classes\n",
    "num_classes = len(classes)\n",
    "print(f\"Classes in the dataset: {classes}\")"
   ],
   "id": "d32cba148e74a33f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Prepare the data loaders.\n",
    "\n",
    "The batch size and the number of workers may be adjusted as needed."
   ],
   "id": "3fa9bb9877fbc9db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ],
   "id": "b2314bd0b402f2e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Euclidean Network\n",
    "\n",
    "Start with a simple Euclidean convolutional network.\n",
    "\n",
    "To compare with hyperbolic networks without too much pain:\n",
    "\n",
    "- it has no batch normalization nor skip connections;\n",
    "- fully connected layers are used at the end instead of e.g. global pooling;\n",
    "- no transfer learning is used."
   ],
   "id": "1980241475517255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Sequence, Tuple\n",
    "from torch.nn import Conv2d, Flatten, Linear, MaxPool2d, ReLU, Sequential\n",
    "\n",
    "\n",
    "def make_euclidean_backbone(\n",
    "    in_channels: int = 3,\n",
    "    conv_channels: Sequence[int] = tuple(),\n",
    "    fc_channels: Sequence[int] = tuple(),\n",
    "    conv_kernel_size: int = 3,\n",
    "    pool_kernel_size: int = 2,\n",
    "    pool_stride: int = 2,\n",
    "    image_size: Tuple[int, int] = (32, 32),\n",
    "    last_activation: bool = False,\n",
    ") -> Tuple[Sequential, int]:\n",
    "    all_conv_channels = (in_channels, *conv_channels)\n",
    "    pool = MaxPool2d(kernel_size=pool_kernel_size, stride=pool_stride)\n",
    "    activation = ReLU()\n",
    "    current_image_size = torch.tensor(image_size)\n",
    "    layers = []\n",
    "    for i in range(len(conv_channels)):\n",
    "        layers.append(\n",
    "            Conv2d(\n",
    "                in_channels=all_conv_channels[i],\n",
    "                out_channels=all_conv_channels[i + 1],\n",
    "                kernel_size=conv_kernel_size,\n",
    "            )\n",
    "        )\n",
    "        current_image_size -= conv_kernel_size - 1\n",
    "        layers.append(activation)\n",
    "        layers.append(pool)\n",
    "        current_image_size //= pool_stride\n",
    "    layers.append(Flatten())\n",
    "    all_fc_channels = (all_conv_channels[-1] * current_image_size.prod(), *fc_channels)\n",
    "    for i in range(len(fc_channels)):\n",
    "        layers.append(\n",
    "            Linear(in_features=all_fc_channels[i], out_features=all_fc_channels[i + 1])\n",
    "        )\n",
    "        if i + 1 < len(fc_channels) or last_activation:\n",
    "            layers.append(activation)\n",
    "    return Sequential(*layers), all_fc_channels[-1]\n",
    "\n",
    "\n",
    "def make_euclidean_net(\n",
    "    out_channels: int = 1,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> Sequential:\n",
    "    backbone, backbone_channels = make_euclidean_backbone(*args, **kwargs)\n",
    "    head = Linear(in_features=backbone_channels, out_features=out_channels)\n",
    "    return Sequential(backbone, head)\n"
   ],
   "id": "e39642e35217e38d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
